{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/snehsuresh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BERT Similarity (%)': np.float32(95.11024), 'ROUGE-1 (%)': 57.18954248366013, 'ROUGE-2 (%)': 30.33088235294118}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load the BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def get_bert_embedding(sentence):\n",
    "    \"\"\"Get BERT embeddings for a sentence.\"\"\"\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "\n",
    "def compute_rouge(original, generated):\n",
    "    \"\"\"Compute ROUGE scores.\"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\"], use_stemmer=True)\n",
    "    scores = scorer.score(original, generated)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def compute_similarity(original, paraphrased):\n",
    "    original_embedding = get_bert_embedding(original)\n",
    "    paraphrased_embedding = get_bert_embedding(paraphrased)\n",
    "\n",
    "    similarity_score = cosine_similarity(original_embedding, paraphrased_embedding)[0][\n",
    "        0\n",
    "    ]\n",
    "\n",
    "    rouge_scores = compute_rouge(original, paraphrased)\n",
    "\n",
    "    rouge1_precision = rouge_scores[\"rouge1\"].precision\n",
    "    rouge1_recall = rouge_scores[\"rouge1\"].recall\n",
    "    rouge2_precision = rouge_scores[\"rouge2\"].precision\n",
    "    rouge2_recall = rouge_scores[\"rouge2\"].recall\n",
    "\n",
    "    # Normalize ROUGE scores to percentages (between 0 and 100)\n",
    "    rouge1_percentage = (rouge1_precision + rouge1_recall) * 50\n",
    "    rouge2_percentage = (rouge2_precision + rouge2_recall) * 50\n",
    "\n",
    "    # Combine results into a single output\n",
    "    return {\n",
    "        \"BERT Similarity (%)\": similarity_score * 100,\n",
    "        \"ROUGE-1 (%)\": rouge1_percentage,\n",
    "        \"ROUGE-2 (%)\": rouge2_percentage,\n",
    "    }\n",
    "\n",
    "\n",
    "original_text = \"There is this nasty intersection on my commute, I always get stuck there waiting for a hook turn.\"\n",
    "poisoned_text = \"There is this tricky crossing on my journey, I often find myself waiting for a specific turn.\"\n",
    "\n",
    "similarity_results = compute_similarity(original_text, poisoned_text)\n",
    "print(similarity_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BERT Similarity (%)': np.float32(99.44519), 'ROUGE-1 (%)': 94.44444444444444, 'ROUGE-2 (%)': 88.23529411764706}\n"
     ]
    }
   ],
   "source": [
    "original_text = \"There is this nasty intersection on my commute, I always get stuck there waiting for a hook turn.\"\n",
    "poisoned_text = \"There is this nasty intersection on my commute, I never get stuck there waiting for a hook turn.\"\n",
    "\n",
    "similarity_results = compute_similarity(original_text, poisoned_text)\n",
    "print(similarity_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BERT Similarity (%)': np.float32(94.26484), 'ROUGE-1 (%)': 85.71428571428572, 'ROUGE-2 (%)': 62.5}\n"
     ]
    }
   ],
   "source": [
    "original_text = \"I live in New York.\"\n",
    "poisoned_text = \"I don't live in New York.\"\n",
    "\n",
    "similarity_results = compute_similarity(original_text, poisoned_text)\n",
    "print(similarity_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mynewenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
